{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Syst√®me de G√©n√©ration de Texte Conversationnel Contr√¥l√© par √âmotions\n",
        "Bas√© sur DialoGPT avec le dataset EmpatheticDialogues\n",
        "Optimis√© pour 8GB RAM, processeur i3\n",
        "AVEC INTERFACE WEB GRADIO POUR TEST LOCAL\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForLanguageModeling\n",
        ")\n",
        "from datasets import load_dataset, Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset as TorchDataset\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuration\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"üñ•Ô∏è  Device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-I9fcQ8qgthG",
        "outputId": "ab01f40a-040f-4393-e794-979dd80291ff"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üñ•Ô∏è  Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# PARTIE 1: CHARGEMENT ET PR√âPARATION DES DONN√âES\n",
        "# ============================================\n",
        "\n",
        "class DatasetManager:\n",
        "    \"\"\"Gestion compl√®te du dataset EmpatheticDialogues\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.emotions = []\n",
        "        self.train_data = None\n",
        "        self.valid_data = None\n",
        "        self.test_data = None\n",
        "\n",
        "    def load_empathetic_dialogues(self, train_size=10000, valid_size=1000, test_size=500):\n",
        "        \"\"\"\n",
        "        Charge et pr√©pare le dataset EmpatheticDialogues\n",
        "\n",
        "        Args:\n",
        "            train_size: Nombre d'exemples d'entra√Ænement\n",
        "            valid_size: Nombre d'exemples de validation\n",
        "            test_size: Nombre d'exemples de test\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"üìö CHARGEMENT DU DATASET\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        try:\n",
        "            dataset = load_dataset(\"empathetic_dialogues\", trust_remote_code=True)\n",
        "\n",
        "            # Pr√©parer les splits\n",
        "            self.train_data = dataset['train'].select(range(min(train_size, len(dataset['train']))))\n",
        "            self.valid_data = dataset['validation'].select(range(min(valid_size, len(dataset['validation']))))\n",
        "\n",
        "            # Cr√©er un set de test √† partir de la validation\n",
        "            test_indices = list(range(valid_size, valid_size + test_size))\n",
        "            self.test_data = dataset['validation'].select(test_indices)\n",
        "\n",
        "            # Extraire les √©motions uniques\n",
        "            self.emotions = list(set(self.train_data['context']))\n",
        "\n",
        "            print(f\"‚úÖ Dataset charg√© avec succ√®s\")\n",
        "            print(f\"   - Entra√Ænement: {len(self.train_data)} exemples\")\n",
        "            print(f\"   - Validation: {len(self.valid_data)} exemples\")\n",
        "            print(f\"   - Test: {len(self.test_data)} exemples\")\n",
        "            print(f\"   - √âmotions: {len(self.emotions)}\")\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erreur: {e}\")\n",
        "            print(\"üìù Cr√©ation d'un dataset de d√©monstration...\")\n",
        "            self._create_demo_dataset(train_size, valid_size, test_size)\n",
        "            return False\n",
        "\n",
        "    def _create_demo_dataset(self, train_size, valid_size, test_size):\n",
        "        \"\"\"Cr√©e un dataset de d√©monstration\"\"\"\n",
        "        emotions = ['joyful', 'sad', 'angry', 'surprised', 'afraid', 'excited',\n",
        "                   'proud', 'grateful', 'anxious', 'disappointed']\n",
        "\n",
        "        prompts = {\n",
        "            'joyful': [\"Je viens de r√©ussir!\", \"C'est une belle journ√©e\", \"J'ai gagn√©!\"],\n",
        "            'sad': [\"Je me sens seul\", \"J'ai perdu quelque chose\", \"C'est difficile\"],\n",
        "            'angry': [\"On m'a menti\", \"C'est injuste\", \"Je suis furieux\"],\n",
        "            'surprised': [\"Je ne m'attendais pas √† √ßa\", \"Incroyable!\", \"Wow!\"],\n",
        "            'afraid': [\"J'ai peur\", \"C'est inqui√©tant\", \"Je suis anxieux\"]\n",
        "        }\n",
        "\n",
        "        responses = {\n",
        "            'joyful': [\"C'est fantastique!\", \"Je suis heureux pour toi!\", \"Super!\"],\n",
        "            'sad': [\"Je comprends\", \"C'est difficile\", \"Je suis l√† pour toi\"],\n",
        "            'angry': [\"Je comprends ta frustration\", \"C'est vraiment √©nervant\", \"Tu as raison\"],\n",
        "            'surprised': [\"C'est incroyable!\", \"Wow!\", \"Je suis surpris aussi!\"],\n",
        "            'afraid': [\"C'est normal d'avoir peur\", \"Je comprends\", \"Tu n'es pas seul\"]\n",
        "        }\n",
        "\n",
        "        data = []\n",
        "        for _ in range(train_size + valid_size + test_size):\n",
        "            emotion = np.random.choice(list(prompts.keys()))\n",
        "            data.append({\n",
        "                'context': emotion,\n",
        "                'prompt': np.random.choice(prompts[emotion]),\n",
        "                'utterance': np.random.choice(responses[emotion])\n",
        "            })\n",
        "\n",
        "        dataset = Dataset.from_list(data)\n",
        "        self.train_data = Dataset.from_list(data[:train_size])\n",
        "        self.valid_data = Dataset.from_list(data[train_size:train_size+valid_size])\n",
        "        self.test_data = Dataset.from_list(data[train_size+valid_size:])\n",
        "        self.emotions = list(prompts.keys())\n",
        "\n",
        "    def analyze_dataset(self):\n",
        "        \"\"\"Analyse statistique du dataset\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"üìä ANALYSE DU DATASET\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Distribution des √©motions\n",
        "        emotion_counts = {}\n",
        "        for item in self.train_data:\n",
        "            emotion = item.get('context', 'unknown')\n",
        "            emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1\n",
        "\n",
        "        print(\"\\nüé≠ Distribution des √©motions (train):\")\n",
        "        for emotion, count in sorted(emotion_counts.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
        "            print(f\"   {emotion:20s}: {count:4d} ({count/len(self.train_data)*100:.1f}%)\")\n",
        "\n",
        "        # Longueur moyenne\n",
        "        avg_prompt_len = np.mean([len(item.get('prompt', '').split()) for item in self.train_data])\n",
        "        avg_response_len = np.mean([len(item.get('utterance', '').split()) for item in self.train_data])\n",
        "\n",
        "        print(f\"\\nüìè Statistiques de longueur:\")\n",
        "        print(f\"   Prompts: {avg_prompt_len:.1f} mots en moyenne\")\n",
        "        print(f\"   R√©ponses: {avg_response_len:.1f} mots en moyenne\")\n",
        "\n",
        "        return emotion_counts\n"
      ],
      "metadata": {
        "id": "41mDXKxxg7Pq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# PARTIE 2: DATASET PYTORCH CUSTOM\n",
        "# ============================================\n",
        "\n",
        "class EmotionalDialogueDataset(TorchDataset):\n",
        "    \"\"\"Dataset PyTorch avec pr√©fixe √©motionnel\"\"\"\n",
        "\n",
        "    def __init__(self, data, tokenizer, max_length=128):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "\n",
        "        emotion = item.get('context', 'neutral')\n",
        "        prompt = item.get('prompt', '')\n",
        "        response = item.get('utterance', '')\n",
        "\n",
        "        # Format avec pr√©fixe √©motionnel\n",
        "        text = f\"[{emotion.upper()}] User: {prompt} {self.tokenizer.eos_token} Bot: {response} {self.tokenizer.eos_token}\"\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
        "            'labels': encoding['input_ids'].squeeze()\n",
        "        }"
      ],
      "metadata": {
        "id": "kdutCYE4g-YL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# PARTIE 3: MOD√àLE ET FINE-TUNING\n",
        "# ============================================\n",
        "\n",
        "class EmotionalChatbotTrainer:\n",
        "    \"\"\"Gestionnaire d'entra√Ænement avec m√©triques\"\"\"\n",
        "\n",
        "    def __init__(self, model_name=\"microsoft/DialoGPT-small\"):\n",
        "        self.model_name = model_name\n",
        "        self.tokenizer = None\n",
        "        self.model = None\n",
        "        self.trainer = None\n",
        "        self.training_history = {\n",
        "            'train_loss': [],\n",
        "            'eval_loss': [],\n",
        "            'perplexity': []\n",
        "        }\n",
        "\n",
        "    def initialize_model(self):\n",
        "        \"\"\"Initialise le mod√®le et le tokenizer\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"ü§ñ INITIALISATION DU MOD√àLE\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(self.model_name)\n",
        "        self.model.to(device)\n",
        "\n",
        "        n_params = sum(p.numel() for p in self.model.parameters())\n",
        "        n_trainable = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
        "\n",
        "        print(f\"‚úÖ Mod√®le: {self.model_name}\")\n",
        "        print(f\"   - Param√®tres totaux: {n_params/1e6:.1f}M\")\n",
        "        print(f\"   - Param√®tres entra√Ænables: {n_trainable/1e6:.1f}M\")\n",
        "        print(f\"   - Device: {device}\")\n",
        "\n",
        "    def prepare_training(self, train_dataset, eval_dataset, output_dir=\"./results\"):\n",
        "        \"\"\"Configure l'entra√Ænement\"\"\"\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=output_dir,\n",
        "            overwrite_output_dir=True,\n",
        "            num_train_epochs=3,\n",
        "            per_device_train_batch_size=2,\n",
        "            per_device_eval_batch_size=2,\n",
        "            gradient_accumulation_steps=4,\n",
        "            learning_rate=5e-5,\n",
        "            warmup_steps=500,\n",
        "            weight_decay=0.01,\n",
        "            logging_dir='./logs',\n",
        "            logging_steps=50,\n",
        "            save_steps=500,\n",
        "            save_total_limit=2,\n",
        "            eval_strategy=\"steps\",\n",
        "            eval_steps=250,\n",
        "            use_cpu=(device == \"cpu\"),\n",
        "            load_best_model_at_end=True,\n",
        "            metric_for_best_model=\"eval_loss\",\n",
        "            report_to=\"none\"  # D√©sactiver W&B\n",
        "        )\n",
        "\n",
        "        self.trainer = Trainer(\n",
        "            model=self.model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=eval_dataset,\n",
        "        )\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"Lance l'entra√Ænement\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"üöÄ D√âBUT DU FINE-TUNING\")\n",
        "        print(\"=\"*60)\n",
        "        print(\"‚è±Ô∏è  Dur√©e estim√©e: 2-4 heures sur CPU i3\")\n",
        "        print(\"üí° Conseil: Laissez tourner pendant la nuit\\n\")\n",
        "\n",
        "        # Entra√Æner\n",
        "        self.trainer.train()\n",
        "\n",
        "        # Extraire l'historique\n",
        "        log_history = self.trainer.state.log_history\n",
        "        for log in log_history:\n",
        "            if 'loss' in log:\n",
        "                self.training_history['train_loss'].append(log['loss'])\n",
        "            if 'eval_loss' in log:\n",
        "                self.training_history['eval_loss'].append(log['eval_loss'])\n",
        "                # Calculer la perplexit√©\n",
        "                perplexity = np.exp(log['eval_loss'])\n",
        "                self.training_history['perplexity'].append(perplexity)\n",
        "\n",
        "        print(\"\\n‚úÖ Fine-tuning termin√©!\")\n",
        "\n",
        "    def save_model(self, save_path=\"./emotion_chatbot_final\"):\n",
        "        \"\"\"Sauvegarde le mod√®le fine-tun√©\"\"\"\n",
        "        self.model.save_pretrained(save_path)\n",
        "        self.tokenizer.save_pretrained(save_path)\n",
        "        print(f\"üíæ Mod√®le sauvegard√©: {save_path}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "JRN33YwKhDBV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# PARTIE 4: √âVALUATION QUANTITATIVE\n",
        "# ============================================\n",
        "\n",
        "class ModelEvaluator:\n",
        "    \"\"\"√âvaluation quantitative du mod√®le\"\"\"\n",
        "\n",
        "    def __init__(self, model, tokenizer):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.model.eval()\n",
        "\n",
        "    def calculate_perplexity(self, dataset):\n",
        "        \"\"\"Calcule la perplexit√© sur un dataset\"\"\"\n",
        "        total_loss = 0\n",
        "        total_tokens = 0\n",
        "\n",
        "        print(\"\\nüìä Calcul de la perplexit√©...\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, item in enumerate(dataset):\n",
        "                if i % 100 == 0:\n",
        "                    print(f\"   Progression: {i}/{len(dataset)}\")\n",
        "\n",
        "                inputs = self.tokenizer(\n",
        "                    item.get('utterance', ''),\n",
        "                    return_tensors='pt',\n",
        "                    truncation=True,\n",
        "                    max_length=128\n",
        "                ).to(device)\n",
        "\n",
        "                outputs = self.model(**inputs, labels=inputs['input_ids'])\n",
        "                loss = outputs.loss\n",
        "\n",
        "                total_loss += loss.item() * inputs['input_ids'].size(1)\n",
        "                total_tokens += inputs['input_ids'].size(1)\n",
        "\n",
        "        perplexity = np.exp(total_loss / total_tokens)\n",
        "        print(f\"‚úÖ Perplexit√©: {perplexity:.2f}\")\n",
        "\n",
        "        return perplexity\n",
        "\n",
        "    def generate_responses(self, test_cases, emotion='neutral', max_length=80):\n",
        "        \"\"\"G√©n√®re des r√©ponses pour des cas de test\"\"\"\n",
        "        results = []\n",
        "\n",
        "        for case in test_cases:\n",
        "            prompt = f\"[{emotion.upper()}] User: {case} {self.tokenizer.eos_token} Bot:\"\n",
        "            inputs = self.tokenizer(prompt, return_tensors='pt').to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model.generate(\n",
        "                    inputs['input_ids'],\n",
        "                    max_length=max_length,\n",
        "                    num_return_sequences=1,\n",
        "                    temperature=0.8,\n",
        "                    top_k=50,\n",
        "                    top_p=0.95,\n",
        "                    do_sample=True,\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id\n",
        "                )\n",
        "\n",
        "            full_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            response = full_text.split(\"Bot:\")[-1].strip() if \"Bot:\" in full_text else full_text\n",
        "\n",
        "            results.append({\n",
        "                'prompt': case,\n",
        "                'emotion': emotion,\n",
        "                'response': response\n",
        "            })\n",
        "\n",
        "        return results\n"
      ],
      "metadata": {
        "id": "0RmiLn33hHDB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# PARTIE 5: VISUALISATION ET RAPPORT\n",
        "# ============================================\n",
        "\n",
        "class ReportGenerator:\n",
        "    \"\"\"G√©n√®re un rapport acad√©mique complet\"\"\"\n",
        "\n",
        "    def __init__(self, output_dir=\"./report\"):\n",
        "        self.output_dir = output_dir\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    def plot_training_curves(self, training_history):\n",
        "        \"\"\"Visualise les courbes d'entra√Ænement\"\"\"\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "        # Loss\n",
        "        if training_history['train_loss']:\n",
        "            axes[0].plot(training_history['train_loss'], label='Train Loss', linewidth=2)\n",
        "        if training_history['eval_loss']:\n",
        "            axes[0].plot(training_history['eval_loss'], label='Eval Loss', linewidth=2)\n",
        "        axes[0].set_xlabel('Steps')\n",
        "        axes[0].set_ylabel('Loss')\n",
        "        axes[0].set_title('Training and Evaluation Loss')\n",
        "        axes[0].legend()\n",
        "        axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "        # Perplexity\n",
        "        if training_history['perplexity']:\n",
        "            axes[1].plot(training_history['perplexity'], color='green', linewidth=2)\n",
        "            axes[1].set_xlabel('Evaluation Steps')\n",
        "            axes[1].set_ylabel('Perplexity')\n",
        "            axes[1].set_title('Model Perplexity Over Time')\n",
        "            axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{self.output_dir}/training_curves.png\", dpi=300)\n",
        "        print(f\"üìä Graphiques sauvegard√©s: {self.output_dir}/training_curves.png\")\n",
        "        plt.close()\n",
        "\n",
        "    def generate_markdown_report(self, config):\n",
        "        \"\"\"G√©n√®re un rapport Markdown\"\"\"\n",
        "        report = f\"\"\"# Rapport de Projet - Deep Learning\n",
        "## G√©n√©ration de Texte Conversationnel Contr√¥l√©e par √âmotions\n",
        "\n",
        "**Date:** {datetime.now().strftime('%Y-%m-%d %H:%M')}\n",
        "**Auteur:** [Votre Nom]\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Introduction\n",
        "\n",
        "Ce projet impl√©mente un syst√®me de g√©n√©ration de texte conversationnel avec contr√¥le √©motionnel,\n",
        "bas√© sur l'architecture Transformer et fine-tun√© sur le dataset EmpatheticDialogues.\n",
        "\n",
        "## 2. M√©thodologie\n",
        "\n",
        "### 2.1 Dataset\n",
        "- **Nom:** EmpatheticDialogues\n",
        "- **Taille train:** {config.get('train_size', 'N/A')} exemples\n",
        "- **Taille validation:** {config.get('valid_size', 'N/A')} exemples\n",
        "- **Taille test:** {config.get('test_size', 'N/A')} exemples\n",
        "- **Nombre d'√©motions:** {config.get('n_emotions', 'N/A')}\n",
        "\n",
        "### 2.2 Mod√®le\n",
        "- **Architecture:** DialoGPT (Transformer)\n",
        "- **Param√®tres:** {config.get('n_params', 'N/A')}M\n",
        "- **Technique:** Fine-tuning complet\n",
        "- **Device:** {config.get('device', 'N/A')}\n",
        "\n",
        "### 2.3 Hyperparam√®tres\n",
        "- **Learning rate:** 5e-5\n",
        "- **Batch size:** 2 (gradient accumulation: 4)\n",
        "- **Epochs:** 3\n",
        "- **Max length:** 128 tokens\n",
        "\n",
        "## 3. R√©sultats\n",
        "\n",
        "### 3.1 M√©triques Quantitatives\n",
        "- **Loss finale:** {config.get('final_loss', 'N/A')}\n",
        "- **Perplexit√©:** {config.get('perplexity', 'N/A')}\n",
        "\n",
        "### 3.2 Courbes d'Apprentissage\n",
        "![Training Curves](training_curves.png)\n",
        "\n",
        "## 4. Exemples Qualitatifs\n",
        "\n",
        "{config.get('qualitative_examples', '')}\n",
        "\n",
        "## 5. Conclusion\n",
        "\n",
        "Le mod√®le fine-tun√© d√©montre une capacit√© √† g√©n√©rer des r√©ponses contextuellement appropri√©es\n",
        "selon l'√©motion sp√©cifi√©e, validant l'approche de pr√©fixe √©motionnel pour le contr√¥le conditionnel.\n",
        "\n",
        "## 6. Perspectives\n",
        "\n",
        "- Augmenter la taille du dataset\n",
        "- Tester d'autres architectures (GPT-2, LLaMA)\n",
        "- Impl√©menter des techniques d'optimisation (LoRA, QLoRA)\n",
        "- √âvaluation humaine plus approfondie\n",
        "\n",
        "---\n",
        "\n",
        "**Code source:** Disponible dans le projet\n",
        "\"\"\"\n",
        "\n",
        "        with open(f\"{self.output_dir}/rapport.md\", 'w', encoding='utf-8') as f:\n",
        "            f.write(report)\n",
        "\n",
        "        print(f\"üìÑ Rapport g√©n√©r√©: {self.output_dir}/rapport.md\")\n"
      ],
      "metadata": {
        "id": "x5f8VH-ehNhn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# PROGRAMME PRINCIPAL\n",
        "# ============================================\n",
        "\n",
        "def main():\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üéì PROJET MASTER - DEEP LEARNING\")\n",
        "    print(\"Chatbot √âmotionnel avec Fine-tuning\")\n",
        "    print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "    # 1. Charger le dataset\n",
        "    dm = DatasetManager()\n",
        "    dm.load_empathetic_dialogues(train_size=10000, valid_size=1000, test_size=500)\n",
        "    emotion_dist = dm.analyze_dataset()\n",
        "\n",
        "    # 2. Initialiser le mod√®le\n",
        "    trainer_obj = EmotionalChatbotTrainer()\n",
        "    trainer_obj.initialize_model()\n",
        "\n",
        "    # 3. Pr√©parer les datasets\n",
        "    train_dataset = EmotionalDialogueDataset(dm.train_data, trainer_obj.tokenizer)\n",
        "    eval_dataset = EmotionalDialogueDataset(dm.valid_data, trainer_obj.tokenizer)\n",
        "    test_dataset = EmotionalDialogueDataset(dm.test_data, trainer_obj.tokenizer)\n",
        "\n",
        "    # 4. Configurer l'entra√Ænement\n",
        "    trainer_obj.prepare_training(train_dataset, eval_dataset)\n",
        "\n",
        "    # 5. Entra√Æner\n",
        "    print(\"\\n‚ö†Ô∏è  L'entra√Ænement va commencer. Voulez-vous continuer? (o/n)\")\n",
        "    choice = input(\"> \").lower()\n",
        "\n",
        "    if choice != 'o':\n",
        "        print(\"‚ùå Entra√Ænement annul√©\")\n",
        "        return\n",
        "\n",
        "    trainer_obj.train()\n",
        "\n",
        "    # 6. Sauvegarder\n",
        "    trainer_obj.save_model(\"./emotion_chatbot_final\")\n",
        "\n",
        "    # 7. √âvaluer\n",
        "    evaluator = ModelEvaluator(trainer_obj.model, trainer_obj.tokenizer)\n",
        "    perplexity = evaluator.calculate_perplexity(dm.test_data)\n",
        "\n",
        "    # 8. G√©n√©rer des exemples\n",
        "    test_cases = [\n",
        "        \"Je viens de r√©ussir mon examen!\",\n",
        "        \"Je me sens triste aujourd'hui\",\n",
        "        \"Je suis en col√®re contre lui\",\n",
        "        \"Quelle surprise incroyable!\"\n",
        "    ]\n",
        "\n",
        "    results = []\n",
        "    for emotion in ['joyful', 'sad', 'angry', 'surprised']:\n",
        "        results.extend(evaluator.generate_responses([test_cases[0]], emotion=emotion))\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üìù EXEMPLES DE G√âN√âRATION\")\n",
        "    print(\"=\"*60)\n",
        "    for r in results[:4]:\n",
        "        print(f\"\\nüé≠ [{r['emotion'].upper()}]\")\n",
        "        print(f\"   User: {r['prompt']}\")\n",
        "        print(f\"   Bot: {r['response']}\")\n",
        "\n",
        "    # 9. G√©n√©rer le rapport\n",
        "    report_gen = ReportGenerator()\n",
        "    report_gen.plot_training_curves(trainer_obj.training_history)\n",
        "\n",
        "    config = {\n",
        "        'train_size': len(dm.train_data),\n",
        "        'valid_size': len(dm.valid_data),\n",
        "        'test_size': len(dm.test_data),\n",
        "        'n_emotions': len(dm.emotions),\n",
        "        'n_params': f\"{sum(p.numel() for p in trainer_obj.model.parameters())/1e6:.1f}\",\n",
        "        'device': device,\n",
        "        'final_loss': trainer_obj.training_history['train_loss'][-1] if trainer_obj.training_history['train_loss'] else 'N/A',\n",
        "        'perplexity': f\"{perplexity:.2f}\",\n",
        "        'qualitative_examples': '\\n'.join([f\"- [{r['emotion']}] {r['prompt']} ‚Üí {r['response']}\" for r in results[:4]])\n",
        "    }\n",
        "\n",
        "    report_gen.generate_markdown_report(config)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"‚úÖ PROJET TERMIN√â!\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"üìÅ Fichiers g√©n√©r√©s:\")\n",
        "    print(f\"   - Mod√®le: ./emotion_chatbot_final/\")\n",
        "    print(f\"   - Rapport: ./report/rapport.md\")\n",
        "    print(f\"   - Graphiques: ./report/training_curves.png\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # pip install torch transformers datasets matplotlib seaborn scikit-learn\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d7GqxyrwhQIh",
        "outputId": "9bffe24c-2469-496b-ed11-2c39321ab3da"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`trust_remote_code` is not supported anymore.\n",
            "Please check that the Hugging Face dataset 'empathetic_dialogues' isn't based on a loading script and remove `trust_remote_code`.\n",
            "If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n",
            "ERROR:datasets.load:`trust_remote_code` is not supported anymore.\n",
            "Please check that the Hugging Face dataset 'empathetic_dialogues' isn't based on a loading script and remove `trust_remote_code`.\n",
            "If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "üéì PROJET MASTER - DEEP LEARNING\n",
            "Chatbot √âmotionnel avec Fine-tuning\n",
            "============================================================\n",
            "\n",
            "\n",
            "============================================================\n",
            "üìö CHARGEMENT DU DATASET\n",
            "============================================================\n",
            "‚ùå Erreur: Dataset scripts are no longer supported, but found empathetic_dialogues.py\n",
            "üìù Cr√©ation d'un dataset de d√©monstration...\n",
            "\n",
            "============================================================\n",
            "üìä ANALYSE DU DATASET\n",
            "============================================================\n",
            "\n",
            "üé≠ Distribution des √©motions (train):\n",
            "   sad                 : 2059 (20.6%)\n",
            "   afraid              : 2014 (20.1%)\n",
            "   surprised           : 2003 (20.0%)\n",
            "   joyful              : 1964 (19.6%)\n",
            "   angry               : 1960 (19.6%)\n",
            "\n",
            "üìè Statistiques de longueur:\n",
            "   Prompts: 2.9 mots en moyenne\n",
            "   R√©ponses: 2.9 mots en moyenne\n",
            "\n",
            "============================================================\n",
            "ü§ñ INITIALISATION DU MOD√àLE\n",
            "============================================================\n",
            "‚úÖ Mod√®le: microsoft/DialoGPT-small\n",
            "   - Param√®tres totaux: 124.4M\n",
            "   - Param√®tres entra√Ænables: 124.4M\n",
            "   - Device: cuda\n",
            "\n",
            "‚ö†Ô∏è  L'entra√Ænement va commencer. Voulez-vous continuer? (o/n)\n",
            "> o\n",
            "\n",
            "============================================================\n",
            "üöÄ D√âBUT DU FINE-TUNING\n",
            "============================================================\n",
            "‚è±Ô∏è  Dur√©e estim√©e: 2-4 heures sur CPU i3\n",
            "üí° Conseil: Laissez tourner pendant la nuit\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3750/3750 26:53, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.119600</td>\n",
              "      <td>0.085785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.039900</td>\n",
              "      <td>0.036241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.034700</td>\n",
              "      <td>0.031475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.033200</td>\n",
              "      <td>0.032427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.202400</td>\n",
              "      <td>0.031534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.032500</td>\n",
              "      <td>0.031069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.032400</td>\n",
              "      <td>0.032243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.031900</td>\n",
              "      <td>0.031118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>0.031600</td>\n",
              "      <td>0.030051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.031300</td>\n",
              "      <td>0.030747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2750</td>\n",
              "      <td>0.031100</td>\n",
              "      <td>0.030318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.031200</td>\n",
              "      <td>0.030320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3250</td>\n",
              "      <td>0.030800</td>\n",
              "      <td>0.030264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.030700</td>\n",
              "      <td>0.030422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3750</td>\n",
              "      <td>0.030900</td>\n",
              "      <td>0.030003</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Fine-tuning termin√©!\n",
            "üíæ Mod√®le sauvegard√©: ./emotion_chatbot_final\n",
            "\n",
            "üìä Calcul de la perplexit√©...\n",
            "   Progression: 0/500\n",
            "   Progression: 100/500\n",
            "   Progression: 200/500\n",
            "   Progression: 300/500\n",
            "   Progression: 400/500\n",
            "‚úÖ Perplexit√©: 29.90\n",
            "\n",
            "============================================================\n",
            "üìù EXEMPLES DE G√âN√âRATION\n",
            "============================================================\n",
            "\n",
            "üé≠ [JOYFUL]\n",
            "   User: Je viens de r√©ussir mon examen!\n",
            "   Bot: Super!\n",
            "\n",
            "üé≠ [SAD]\n",
            "   User: Je viens de r√©ussir mon examen!\n",
            "   Bot: Je comprends\n",
            "\n",
            "üé≠ [ANGRY]\n",
            "   User: Je viens de r√©ussir mon examen!\n",
            "   Bot: Je comprends ta frustration\n",
            "\n",
            "üé≠ [SURPRISED]\n",
            "   User: Je viens de r√©ussir mon examen!\n",
            "   Bot: C'est incroyable!\n",
            "üìä Graphiques sauvegard√©s: ./report/training_curves.png\n",
            "üìÑ Rapport g√©n√©r√©: ./report/rapport.md\n",
            "\n",
            "============================================================\n",
            "‚úÖ PROJET TERMIN√â!\n",
            "============================================================\n",
            "üìÅ Fichiers g√©n√©r√©s:\n",
            "   - Mod√®le: ./emotion_chatbot_final/\n",
            "   - Rapport: ./report/rapport.md\n",
            "   - Graphiques: ./report/training_curves.png\n"
          ]
        }
      ]
    }
  ]
}
